{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4223c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"StanfordAIMI/dinov2-base-xray-224\")\n",
    "backbone = AutoModel.from_pretrained(\"StanfordAIMI/dinov2-base-xray-224\")\n",
    "feat_dim = backbone.config.hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8938bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from FusionModels.MLP.MLP import MLP\n",
    "from wrapperModul import wrapperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ae992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_mlp = MLP([1024, 2048, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34511c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in head_mlp.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74653e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in backbone.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f05871",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wrapperModel(backbone, head_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0a453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')  \n",
    "from DataLoader.dataLoader import IntubiertDataset\n",
    "from Train.trainLoop import train_model\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcac3cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INFO_FILE = r\"../Data/PatientInfo/splittedPatientData.xlsx\"\n",
    "IMAGE_PATH = r\"../Data/Patient_Images\"\n",
    "LOG_PATH = r\"Logs/dinov2-base-xray-224HeadTune.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc640e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                             \n",
    "    transforms.ToTensor(),                                        \n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cf9bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IntubiertDataset(IMAGE_PATH,DATA_INFO_FILE , \"train\",transforms=train_transform)\n",
    "val_dataset = IntubiertDataset(IMAGE_PATH, DATA_INFO_FILE, \"val\",transforms=val_transform)\n",
    "test_dataset = IntubiertDataset(IMAGE_PATH, DATA_INFO_FILE, \"test\", transforms=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bee88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, num_workers=20)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, num_workers=20)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492595fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a03b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,          \n",
    "    mode='min',          \n",
    "    factor=0.5,          \n",
    "    patience=2,          \n",
    "    min_lr=1e-6,        \n",
    "    cooldown=0,          \n",
    "    threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa3b7a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, 'cuda', criterion, optimizer, 'best_model.pth', LOG_PATH,scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e851f10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully with non-strict loading\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "checkpoint = torch.load('best_model.pth', weights_only=True)\n",
    "\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "print(\"Model loaded successfully with non-strict loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16096c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.5191\n",
      "Accuracy: 0.7308, F1: 0.5297, AUC: 0.7986\n",
      "Precision: 1.0000, Recall: 0.1250, Specificity: 1.0000\n",
      "Confusion Matrix:\n",
      "[[18  0]\n",
      " [ 7  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from Test_Phrease.Eval.testEvaluate import evaluate_model_on_testset\n",
    "\n",
    "test_results=evaluate_model_on_testset(model, 'dinov2-base-xray-224HeadTune', test_dataloader, 'cuda', criterion, 'testeval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0036585f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Test_Phrease.Eval_Results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTest_Phrease\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEval_Results\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcatModelTestResults\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_metrics_to_excel\n\u001b[1;32m      3\u001b[0m save_metrics_to_excel(test_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../ModelResultsDocs/testresults.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Test_Phrease.Eval_Results'"
     ]
    }
   ],
   "source": [
    "from Test_Phrease.Eval_Results.concatModelTestResults import save_metrics_to_excel\n",
    "\n",
    "save_metrics_to_excel(test_results, '../ModelResultsDocs/testresults.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
